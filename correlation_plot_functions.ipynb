{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from __future__ import division, print_function\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import scipy.stats as scs\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('max_colwidth',200)\n",
    "import datetime as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CustomParser(data):\n",
    "    \"\"\"\n",
    "    utility function to convert a pandas column from str to dict while reading data from a CSV\n",
    "    \"\"\"\n",
    "    import json\n",
    "    j1 = json.loads(data)\n",
    "    return j1\n",
    "\n",
    "class AdhocCorrelationUtilities(object):\n",
    "    \"\"\"\n",
    "    this class includes functions to output analysis for the feature-class correlation notebook. \n",
    "    \n",
    "    functions that identify numerical and categorical attributes in the dataset are needed \n",
    "    to separate them by type and use each type with relevant analysis / plots\n",
    "    \n",
    "    the constructor of the class loads the dataset, initializes variables, \n",
    "    and converts the payload column to a dictionary type.\n",
    "    it also performs undersampling on the target attribute if usample is True\n",
    "    \n",
    "    function get_df() parses the payload dict type column to prepares all features for analysis\n",
    "    \n",
    "    dataset_csv = the CSV file containing the dataset for analysis. \n",
    "    value_counts_threshold = the value counts threshold that determines whether to consider a feature numerical \n",
    "                             or categorical. Default value is 10.  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_csv, target, usample, value_counts_threshold=10):\n",
    "        \n",
    "        filepath = path.join(os.getcwd(), dataset_csv) \n",
    "        self.features_target_df = pd.read_csv(filepath, converters={'payload':CustomParser}).set_index(['user_id','event_date'], \n",
    "                                                                                     drop=False)\n",
    "        self.value_counts_threshold = value_counts_threshold\n",
    "        self.target = target\n",
    "        self.num_cols = None\n",
    "        self.cat_cols = None\n",
    "        self.anovaDF = None\n",
    "        self.chi2DF = None\n",
    "        \n",
    "        if usample:\n",
    "            false_indices = self.features_target_df[self.features_target_df.subscribed == False].index\n",
    "            sample_size = sum(self.features_target_df.subscribed == True)\n",
    "            random_indices = np.random.choice(false_indices, sample_size, replace=False)\n",
    "            false_sample = self.features_target_df.loc[random_indices]\n",
    "            true_data = self.features_target_df[self.features_target_df.subscribed == True]\n",
    "            self.features_target_df = pd.concat([true_data, false_sample])\n",
    "    \n",
    "    def get_df(self):\n",
    "        self.features_target_df[self.features_target_df['payload'][0].keys()] = self.features_target_df['payload'].apply(pd.Series)\n",
    "        self.features_target_df[self.features_target_df['analytics'][0].keys()] = self.features_target_df['analytics'].apply(pd.Series)\n",
    "        del self.features_target_df['payload']\n",
    "        del self.features_target_df['analytics']\n",
    "        self.features_target_df.columns = [\"user_id\", \"event_date\", \"country\", \"subscribed\", \"industry\", \"time_in_product_mins\", \"campaign\", \n",
    "                           \"device\", \"email_open_rate_percent\", \"referrer_channel\"]\n",
    "        return self.features_target_df\n",
    "    \n",
    "    def get_num_cols_rules(self):\n",
    "        features = [f for f in self.features_target_df.columns.tolist() if not \n",
    "                                    (f.startswith('user_id') \n",
    "                                     or f.startswith('event_date')\n",
    "                                     or f.startswith(self.target))]\n",
    "        featuresDF = self.features_target_df[features]\n",
    "        num_cols = list(featuresDF._get_numeric_data().columns)\n",
    "        #disregard features having value counts less than value_counts_threshold\n",
    "        num_cols_thresh = [f for f in num_cols if featuresDF[f].value_counts().count() >= self.value_counts_threshold]\n",
    "        self.num_cols = num_cols_thresh\n",
    "        return num_cols_thresh\n",
    "    \n",
    "    def get_cat_cols_rules(self):\n",
    "        features = [f for f in self.features_target_df.columns.tolist() if not \n",
    "                                    (f.startswith('user_id') \n",
    "                                     or f.startswith('event_date')\n",
    "                                     or f.startswith(self.target))]\n",
    "        num_cols = self.get_num_cols_rules()\n",
    "        cat_cols = [f for f in features if f not in num_cols]\n",
    "        self.cat_cols = cat_cols\n",
    "        return cat_cols \n",
    "    \n",
    "    # function to create a boxplot\n",
    "    def boxplot(self, target, feature, data):\n",
    "        sns.plt.figure(figsize=(18,10))\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        pal = {c: \"#539caf\" if c == 0 else \"#7663b0\" for c in data[target]}\n",
    "        ax = sns.boxplot(x=target, y=feature, hue=target, palette=pal, data=data)\n",
    "        ax.axes.set_title('Median ' + feature + ' score for each class in target ' + target, fontsize=16)\n",
    "        ax.set_xlabel(target, fontsize=14)\n",
    "        ax.set_ylabel(feature, fontsize=14)\n",
    "        #sns.plt.setp(ax.artists, alpha=.5, linewidth=2, fill=True, edgecolor=\"k\")\n",
    "        sns.plt.show()\n",
    "        \n",
    "    # function to create boxplots for the numerical features against a target\n",
    "    def boxplots(self, target):\n",
    "        num_cols = self.get_num_cols_rules()\n",
    "        data = self.features_target_df\n",
    "        \n",
    "        for i in range(0, len(num_cols)):\n",
    "            df = data[np.isfinite(data[num_cols[i]])]\n",
    "            #discard features with no non-NAN values\n",
    "            if len(df) == 0.0:\n",
    "                continue\n",
    "            #discard features having no min - max difference \n",
    "            if df[num_cols[i]].max() - df[num_cols[i]].min() == 0.0:\n",
    "                continue\n",
    "            self.boxplot(target, num_cols[i], df)\n",
    "    \n",
    "    # function to create an overlaid histogram\n",
    "    def overlaid_histogram(self, data1, data1_name, data1_color, data2, data2_name, data2_color, x_label, y_label, title):\n",
    "        # Set the bounds for the bins so that the two distributions are\n",
    "        # fairly compared\n",
    "        max_nbins = 20\n",
    "        try:\n",
    "            data_range = [min(min(data1), min(data2)), max(max(data1), max(data2))]\n",
    "        except ValueError, e:\n",
    "            print(e)\n",
    "            print(\"skipping feature \" + x_label)\n",
    "            return\n",
    "        binwidth = (data_range[1] - data_range[0]) / max_nbins\n",
    "        try:\n",
    "            bins = np.arange(data_range[0], data_range[1] + binwidth, binwidth)\n",
    "        except ValueError, e:\n",
    "            print(e)\n",
    "            print('skipping feature '+x_label+' ...')\n",
    "            return\n",
    "\n",
    "        # Create the plot\n",
    "        _, ax = plt.subplots(figsize=(18,10))\n",
    "        ax.hist(data1, bins = bins, color = data1_color, alpha = 1, label = data1_name)\n",
    "        ax.hist(data2, bins = bins, color = data2_color, alpha = 0.75, label = data2_name)\n",
    "        ax.set_ylabel(y_label, fontsize=14)\n",
    "        ax.set_xlabel(x_label, fontsize=14)\n",
    "        ax.set_title(title, fontsize=16)\n",
    "        ax.legend(loc = 'best')\n",
    "        \n",
    "    # function to create overlaid histograms for the numerical features against a target\n",
    "    def overlaid_histograms(self, target):\n",
    "        num_cols = self.get_num_cols_rules()\n",
    "        data = self.features_target_df\n",
    "        classes = np.unique(data[target])\n",
    "        if len(classes) > 2:\n",
    "            classes = np.delete(classes, [0])\n",
    "\n",
    "        #print(data[target].value_counts())\n",
    "        #print(len(data))\n",
    "        \n",
    "        for i in range(0, len(num_cols)):\n",
    "            df = data[np.isfinite(data[num_cols[i]])]\n",
    "            #discard features with no non-NAN values\n",
    "            if len(df) == 0.0:\n",
    "                continue\n",
    "            #discard features having no min - max difference \n",
    "            if df[num_cols[i]].max() - df[num_cols[i]].min() == 0.0:\n",
    "                continue\n",
    "            title = 'Distribution of ' + num_cols[i] + ' by ' + target\n",
    "            features_by_target = []\n",
    "            for c in classes:\n",
    "                features_by_target.append(df[df[target] == c][num_cols[i]].values)\n",
    "            self.overlaid_histogram(data1 = features_by_target[0]\n",
    "                               , data1_name = 'class_' + str(classes[0])\n",
    "                               , data1_color = '#539caf'\n",
    "                               , data2 = features_by_target[1]\n",
    "                               , data2_name = 'class_' + str(classes[1])\n",
    "                               , data2_color = '#7663b0'\n",
    "                               , x_label = num_cols[i]\n",
    "                               , y_label = 'Frequency'\n",
    "                               , title = title)\n",
    "            \n",
    "    # function to compute one-way ANOVA statistics for numerical features against categories of a binary target\n",
    "    # the computation is performed using Statsmodels anova_lm function given an ordinary least squares input\n",
    "    def compute_one_way_anova_lm(self, target):\n",
    "        anova_cols = ['feature', 'sum_sq', 'esq_sm', 'F', 'PR(>F)']\n",
    "        anovaDF = pd.DataFrame(columns=anova_cols)\n",
    "        num_cols = self.get_num_cols_rules()\n",
    "        data = self.features_target_df\n",
    "            \n",
    "        #make sure the target is binary\n",
    "        classes = np.unique(data[target])\n",
    "        if len(classes) > 2:\n",
    "            classes = np.delete(classes, [0])\n",
    "        data = data[data[target].isin(classes.tolist())]\n",
    "        \n",
    "        #make sure the target has an str dtype\n",
    "        data.loc[:,target] = data.loc[:,target].apply(str)\n",
    "        \n",
    "        for i in range(0, len(num_cols)):\n",
    "            df = data[np.isfinite(data[num_cols[i]])]\n",
    "            #discard features with no non-NAN values\n",
    "            if len(df) == 0.0:\n",
    "                continue\n",
    "            #discard features having no min - max difference \n",
    "            if df[num_cols[i]].max() - df[num_cols[i]].min() == 0.0:\n",
    "                continue\n",
    "            mod = ols(num_cols[i] +' ~ ' + target,\n",
    "                            data=df).fit()\n",
    "\n",
    "            aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "            esq_sm = aov_table['sum_sq'][0]/(aov_table['sum_sq'][0]+aov_table['sum_sq'][1])\n",
    "            temp = pd.DataFrame({'feature': num_cols[i], \n",
    "                                 'sum_sq': round(aov_table['sum_sq'][0], 3),\n",
    "                                 'esq_sm': round(esq_sm, 3),\n",
    "                                 'F': round(aov_table['F'][0], 3),\n",
    "                                 'PR(>F)': round(aov_table['PR(>F)'][0], 6)\n",
    "                                }, index=[0])\n",
    "            anovaDF = pd.concat([anovaDF, temp])\n",
    "            \n",
    "        print ('one_way_anova_lm statistics computed for %d out of %d features' % (len(anovaDF), len(num_cols)) )\n",
    "        self.anovaDF = anovaDF\n",
    "    \n",
    "    # call compute_one_way_anova_lm() given target and show the resulted dataframe\n",
    "    # order_by is one of ['sum_sq', 'esq_sm', 'F', 'PR(>F)']\n",
    "    # ascending is one of [True, False]\n",
    "    def show_one_way_anova_lm(self, target, order_by, ascending):\n",
    "        self.compute_one_way_anova_lm(target)\n",
    "        self.anovaDF = self.anovaDF.sort_values(by=order_by, ascending=ascending)\n",
    "        self.anovaDF = self.anovaDF.reset_index(drop=True)\n",
    "        display(self.anovaDF[['feature', 'sum_sq', 'esq_sm', 'F', 'PR(>F)']])\n",
    "        \n",
    "    # function to create a contingency table between a categorical feature and target attribute\n",
    "    def contingency_table(self, target, feature, prop):\n",
    "        data = self.features_target_df\n",
    "        \n",
    "        #print(data[target].value_counts())\n",
    "        \n",
    "        #show either value counts or proportions\n",
    "        if prop:\n",
    "            print(\"Proportions of feature \" + feature + \" per each class of target \" + target)\n",
    "            display(pd.crosstab(data[target], data[feature]).apply(lambda r: r/r.sum(), axis=0))\n",
    "        else:\n",
    "            print(\"Value counts of feature \" + feature + \" per each class of target \" + target)\n",
    "            display(pd.crosstab(data[target], data[feature]))\n",
    "                \n",
    "    # function to create contingency tables for the categorical features against a target\n",
    "    # if prop is True, the feature proportions per target class are displayed instead of the actual counts\n",
    "    def contingency_tables(self, target, prop):\n",
    "        cat_cols = self.get_cat_cols_rules()\n",
    "        data = self.features_target_df\n",
    "        for i in range(0, len(cat_cols)):\n",
    "            #discard features having no data\n",
    "            if len(data[cat_cols[i]].tolist()) == 0:\n",
    "                continue\n",
    "            #discard features having no more than 1 value\n",
    "            if data[cat_cols[i]].value_counts().count() <= 1:\n",
    "                continue\n",
    "            self.contingency_table(target, cat_cols[i], prop)\n",
    "    \n",
    "    # Define a function for a stacked bar plot\n",
    "    def stackedbarplot(self, x_data, y_data_list, y_data_names, colors, x_label, y_label, title):\n",
    "        _, ax = plt.subplots(figsize=(18,10))\n",
    "        # Draw bars, one category at a time\n",
    "        for i in range(0, len(y_data_list)):\n",
    "            n=len(x_data)\n",
    "            ind=np.arange(n)\n",
    "            width=0.10\n",
    "            if i == 0:\n",
    "                ax.bar(ind, y_data_list[i], color = colors[i], align = 'center', label = y_data_names[i])\n",
    "            else:\n",
    "                # For each category after the first, the bottom of the\n",
    "                # bar will be the top of the last category\n",
    "                ax.bar(ind, y_data_list[i], color = colors[i], bottom = y_data_list[i - 1], align = 'center', \n",
    "                       label = y_data_names[i])\n",
    "        plt.xticks(ind+width/2,tuple(x_data))\n",
    "        ax.set_ylabel(y_label, fontsize=14)\n",
    "        ax.set_xlabel(x_label, fontsize=14)\n",
    "        ax.set_title(title, fontsize=16)\n",
    "        ax.legend(loc = 'upper right')\n",
    "        plt.show()\n",
    "    \n",
    "    # function to create  plots for the categorical features against a target\n",
    "    def stackedbarplots(self, target):\n",
    "        cat_cols = self.get_cat_cols_rules()\n",
    "        for i in range(0, len(cat_cols)):\n",
    "            data = self.features_target_df\n",
    "            #discard features having no data\n",
    "            if len(data[cat_cols[i]].tolist()) == 0:\n",
    "                continue\n",
    "            #discard features having no more than 1 value\n",
    "            if data[cat_cols[i]].value_counts().count() <= 1:\n",
    "                continue\n",
    "            \n",
    "            class_agg_by_feature = pd.crosstab(data[cat_cols[i]], data[target])\n",
    "            class_agg_by_feature.columns = ['class_0', 'class_1']\n",
    "            class_agg_by_feature['total'] = class_agg_by_feature['class_0'] + class_agg_by_feature['class_1']\n",
    "            class_agg_by_feature['c0_prop'] = class_agg_by_feature['class_0'] / class_agg_by_feature['total']\n",
    "            class_agg_by_feature['c1_prop'] = class_agg_by_feature['class_1'] / class_agg_by_feature['total']\n",
    "            \n",
    "            # Call the function to create plot\n",
    "            title = 'Proportion of target ' + str(target) + ' classes'\n",
    "            self.stackedbarplot(x_data = class_agg_by_feature.index.values\n",
    "                           , y_data_list = [class_agg_by_feature['c0_prop'].tolist(), \n",
    "                                            class_agg_by_feature['c1_prop'].tolist()]\n",
    "                           , y_data_names = ['class_0', 'class_1']\n",
    "                           , colors = ['#539caf', '#7663b0']\n",
    "                           , x_label = cat_cols[i]\n",
    "                           , y_label = 'Proportion'\n",
    "                           , title = title)\n",
    "            \n",
    "    # returns range for a series for chi_square test\n",
    "    def categories(self, series):\n",
    "        return range(int(series.min()), int(series.max()) + 1)\n",
    "\n",
    "    # function to compute chi_square test of independence of col1 & col2 variables in a dataframe df\n",
    "    # returns tuple (chi2, p) representing the chi2 test statistic and the p-value of the test, respectively\n",
    "    # uses scipy.stats.chi2_contingency\n",
    "    def chi_square_of_df_cols(self, df, col1, col2):\n",
    "        df_col1, df_col2 = df[col1], df[col2]\n",
    "\n",
    "        result = [[sum((df_col1 == cat1) & (df_col2 == cat2))\n",
    "                   for cat2 in self.categories(df_col2)]\n",
    "                  for cat1 in self.categories(df_col1)]\n",
    "\n",
    "        return (scs.chi2_contingency(result)[0], scs.chi2_contingency(result)[1]) \n",
    "    \n",
    "    # TODO\n",
    "    # calls function chi_square_of_df_cols() for every categorical feature and the target \n",
    "    def compute_chi_square(self, target):\n",
    "        chi2_cols = ['feature', 'chi2', 'Pr(>chi)']\n",
    "        chi2DF = pd.DataFrame(columns=chi2_cols)\n",
    "        cat_cols = self.get_cat_cols_rules()\n",
    "        data = self.features_target_df\n",
    "            \n",
    "        #make sure the target is binary\n",
    "        classes = np.unique(data[target])\n",
    "        if len(classes) > 2:\n",
    "            classes = np.delete(classes, [0])\n",
    "            data = data[data[target].isin(classes.tolist())]\n",
    "            \n",
    "        #make sure the target has an int dtype\n",
    "        data.loc[:,target] = data.loc[:,target].apply(int)\n",
    "        \n",
    "        for i in range(0, len(cat_cols)):\n",
    "            #discard features having no data\n",
    "            if len(data[cat_cols[i]].tolist()) == 0:\n",
    "                continue\n",
    "            #discard features having no more than 1 value\n",
    "            if data[cat_cols[i]].value_counts().count() <= 1:\n",
    "                continue\n",
    "            \n",
    "            #make sure the feature has an str dtype\n",
    "            data.loc[:,cat_cols[i]] = data.loc[:,cat_cols[i]].apply(str)\n",
    "            \n",
    "            #apply feature mapping from str to int sequence\n",
    "            mapping = {} \n",
    "            for j in range(0, len(data[cat_cols[i]].unique().tolist())):\n",
    "                mapping[data[cat_cols[i]].unique().tolist()[j]] = j\n",
    "\n",
    "            data = data.replace({cat_cols[i]: mapping})\n",
    "            \n",
    "            (chi2, p) = self.chi_square_of_df_cols(data, cat_cols[i], target)\n",
    "            \n",
    "            temp = pd.DataFrame({'feature': cat_cols[i], \n",
    "                                 'chi2': round(chi2, 3),\n",
    "                                 'Pr(>chi)': round(p, 3)\n",
    "                                }, index=[0])\n",
    "            chi2DF = pd.concat([chi2DF, temp])\n",
    "            \n",
    "        print ('chi_square_of_df_cols computed for %d out of %d features' % (len(chi2DF), len(cat_cols)) )\n",
    "        self.chi2DF = chi2DF\n",
    "        \n",
    "    # call compute_chi_square() given target and show the resulted dataframe\n",
    "    # order_by is one of ['chi2', 'Pr(>chi)']\n",
    "    # ascending is one of [True, False]\n",
    "    def show_chi_square_scs(self, target, order_by, ascending):\n",
    "        self.compute_chi_square(target)\n",
    "        self.chi2DF = self.chi2DF.sort_values(by=order_by, ascending=ascending)\n",
    "        self.chi2DF = self.chi2DF.reset_index(drop=True)\n",
    "        display(self.chi2DF[['feature', 'chi2', 'Pr(>chi)']])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
